diff --git a/cmd/promtool/main.go b/cmd/promtool/main.go
index d227a04a8..86381e831 100644
--- a/cmd/promtool/main.go
+++ b/cmd/promtool/main.go
@@ -76,9 +76,7 @@ var promqlEnableDelayedNameRemoval = false
 
 func init() {
 	// This can be removed when the legacy global mode is fully deprecated.
-
-	//nolint:staticcheck
-
+	//nolint:staticcheck // SA1019: model.NameValidationScheme is deprecated but needed for legacy support
 	model.NameValidationScheme = model.UTF8Validation
 }
 
@@ -487,21 +485,15 @@ func main() {
 	parsedCmd := kingpin.MustParse(app.Parse(os.Args[1:]))
 
 	var p printer
-
 	switch *queryCmdFmt {
-
 	case "json":
 
 		p = &jsonPrinter{}
-
 	case "promql":
 
 		p = &promqlPrinter{}
-
 	}
-
 	if httpConfigFilePath != "" {
-
 		if serverURL != nil && serverURL.User.Username() != "" {
 			kingpin.Fatalf("Cannot set base auth in the server URL and use a http.config.file at the same time")
 		}
@@ -517,103 +509,76 @@ func main() {
 		if err != nil {
 			kingpin.Fatalf("Failed to create a new HTTP round tripper: %v", err)
 		}
-
 	}
-
 	for _, f := range *featureList {
 
 		opts := strings.Split(f, ",")
-
 		for _, o := range opts {
 			switch o {
-
 			case "promql-experimental-functions":
 
 				parser.EnableExperimentalFunctions = true
-
 			case "promql-delayed-name-removal":
 
 				promqlEnableDelayedNameRemoval = true
-
 			case "":
 
 				continue
-
 			default:
 
 				fmt.Printf("  WARNING: Unknown feature passed to --enable-feature: %s", o)
-
 			}
 		}
-
 	}
-
 	switch parsedCmd {
-
 	case sdCheckCmd.FullCommand():
 
 		os.Exit(CheckSD(*sdConfigFile, *sdJobName, *sdTimeout, prometheus.DefaultRegisterer))
-
 	case checkConfigCmd.FullCommand():
 
 		os.Exit(CheckConfig(*agentMode, *checkConfigSyntaxOnly, newConfigLintConfig(*checkConfigLint, *checkConfigLintFatal, *checkConfigIgnoreUnknownFields, model.Duration(*checkLookbackDelta)), *configFiles...))
-
 	case checkServerHealthCmd.FullCommand():
 
 		os.Exit(checkErr(CheckServerStatus(serverURL, checkHealth, httpRoundTripper)))
-
 	case checkServerReadyCmd.FullCommand():
 
 		os.Exit(checkErr(CheckServerStatus(serverURL, checkReadiness, httpRoundTripper)))
-
 	case checkWebConfigCmd.FullCommand():
 
 		os.Exit(CheckWebConfig(*webConfigFiles...))
-
 	case checkRulesCmd.FullCommand():
 
 		os.Exit(CheckRules(newRulesLintConfig(*checkRulesLint, *checkRulesLintFatal, *checkRulesIgnoreUnknownFields), *ruleFiles...))
-
 	case checkMetricsCmd.FullCommand():
 
 		os.Exit(CheckMetrics(*checkMetricsExtended))
-
 	case pushMetricsCmd.FullCommand():
 
 		os.Exit(PushMetrics(remoteWriteURL, httpRoundTripper, *pushMetricsHeaders, *pushMetricsTimeout, *pushMetricsLabels, *metricFiles...))
-
 	case queryInstantCmd.FullCommand():
 
 		os.Exit(QueryInstant(serverURL, httpRoundTripper, *queryInstantExpr, *queryInstantTime, p))
-
 	case queryRangeCmd.FullCommand():
 
 		os.Exit(QueryRange(serverURL, httpRoundTripper, *queryRangeHeaders, *queryRangeExpr, *queryRangeBegin, *queryRangeEnd, *queryRangeStep, p))
-
 	case querySeriesCmd.FullCommand():
 
 		os.Exit(QuerySeries(serverURL, httpRoundTripper, *querySeriesMatch, *querySeriesBegin, *querySeriesEnd, p))
-
 	case debugPprofCmd.FullCommand():
 
 		os.Exit(debugPprof(*debugPprofServer))
-
 	case debugMetricsCmd.FullCommand():
 
 		os.Exit(debugMetrics(*debugMetricsServer))
-
 	case debugAllCmd.FullCommand():
 
 		os.Exit(debugAll(*debugAllServer))
-
 	case queryLabelsCmd.FullCommand():
 
 		os.Exit(QueryLabels(serverURL, httpRoundTripper, *queryLabelsMatch, *queryLabelsName, *queryLabelsBegin, *queryLabelsEnd, p))
-
 	case testRulesCmd.FullCommand():
 
 		results := io.Discard
-
 		if *junitOutFile != nil {
 			results = *junitOutFile
 		}
@@ -646,63 +611,50 @@ func main() {
 
 			*testRulesFiles...),
 		)
-
 	case tsdbBenchWriteCmd.FullCommand():
 
 		os.Exit(checkErr(benchmarkWrite(*benchWriteOutPath, *benchSamplesFile, *benchWriteNumMetrics, *benchWriteNumScrapes)))
-
 	case tsdbAnalyzeCmd.FullCommand():
 
 		os.Exit(checkErr(analyzeBlock(ctx, *analyzePath, *analyzeBlockID, *analyzeLimit, *analyzeRunExtended, *analyzeMatchers)))
-
 	case tsdbListCmd.FullCommand():
 
 		os.Exit(checkErr(listBlocks(*listPath, *listHumanReadable)))
-
 	case tsdbDumpCmd.FullCommand():
 
 		os.Exit(checkErr(dumpSamples(ctx, *dumpPath, *dumpSandboxDirRoot, *dumpMinTime, *dumpMaxTime, *dumpMatch, formatSeriesSet)))
-
 	case tsdbDumpOpenMetricsCmd.FullCommand():
 
 		os.Exit(checkErr(dumpSamples(ctx, *dumpOpenMetricsPath, *dumpOpenMetricsSandboxDirRoot, *dumpOpenMetricsMinTime, *dumpOpenMetricsMaxTime, *dumpOpenMetricsMatch, formatSeriesSetOpenMetrics)))
 
 	// TODO(aSquare14): Work on adding support for custom block size.
-
 	case openMetricsImportCmd.FullCommand():
 
 		os.Exit(backfillOpenMetrics(*importFilePath, *importDBPath, *importHumanReadable, *importQuiet, *maxBlockDuration, *openMetricsLabels))
-
 	case importRulesCmd.FullCommand():
 
 		os.Exit(checkErr(importRules(serverURL, httpRoundTripper, *importRulesStart, *importRulesEnd, *importRulesOutputDir, *importRulesEvalInterval, *maxBlockDuration, *importRulesFiles...)))
-
 	case queryAnalyzeCmd.FullCommand():
 
 		os.Exit(checkErr(queryAnalyzeCfg.run(serverURL, httpRoundTripper)))
-
 	case documentationCmd.FullCommand():
 
 		os.Exit(checkErr(documentcli.GenerateMarkdown(app.Model(), os.Stdout)))
-
 	case promQLFormatCmd.FullCommand():
 
 		checkExperimental(*experimental)
 
 		os.Exit(checkErr(formatPromQL(*promQLFormatQuery)))
-
 	case promQLLabelsSetCmd.FullCommand():
 
 		checkExperimental(*experimental)
 
 		os.Exit(checkErr(labelsSetPromQL(*promQLLabelsSetQuery, *promQLLabelsSetType, *promQLLabelsSetName, *promQLLabelsSetValue)))
-
 	case promQLLabelsDeleteCmd.FullCommand():
 
 		checkExperimental(*experimental)
 
 		os.Exit(checkErr(labelsDeletePromQL(*promQLLabelsDeleteQuery, *promQLLabelsDeleteName)))
-
 	}
 }
 
@@ -712,7 +664,6 @@ func checkExperimental(f bool) {
 		fmt.Fprintln(os.Stderr, "This command is experimental and requires the --experimental flag to be set.")
 
 		os.Exit(1)
-
 	}
 }
 
@@ -736,24 +687,18 @@ func newRulesLintConfig(stringVal string, fatal, ignoreUnknownFields bool) rules
 
 		ignoreUnknownFields: ignoreUnknownFields,
 	}
-
 	for _, setting := range items {
 		switch setting {
-
 		case lintOptionAll:
 
 			ls.all = true
-
 		case lintOptionDuplicateRules:
 
 			ls.duplicateRules = true
-
 		case lintOptionNone:
-
 		default:
 
 			fmt.Printf("WARNING: unknown lint option: %q\n", setting)
-
 		}
 	}
 
@@ -780,37 +725,28 @@ func newConfigLintConfig(optionsStr string, fatal, ignoreUnknownFields bool, loo
 	lintNone := false
 
 	var rulesOptions []string
-
 	for _, option := range strings.Split(optionsStr, ",") {
 		switch option {
-
 		case lintOptionAll, lintOptionTooLongScrapeInterval:
 
 			c.lookbackDelta = lookbackDelta
-
 			if option == lintOptionAll {
 				rulesOptions = append(rulesOptions, lintOptionAll)
 			}
-
 		case lintOptionNone:
 
 			lintNone = true
-
 		default:
 
 			rulesOptions = append(rulesOptions, option)
-
 		}
 	}
-
 	if lintNone {
 
 		c.lookbackDelta = 0
 
 		rulesOptions = nil
-
 	}
-
 	if len(rulesOptions) > 0 {
 		c.rulesLintConfig = newRulesLintConfig(strings.Join(rulesOptions, ","), fatal, ignoreUnknownFields)
 	}
@@ -839,7 +775,6 @@ func CheckServerStatus(serverURL *url.URL, checkEndpoint string, roundTripper ht
 		fmt.Fprintln(os.Stderr, "error creating API client:", err)
 
 		return err
-
 	}
 
 	request, err := http.NewRequest(http.MethodGet, config.Address, nil)
@@ -855,7 +790,6 @@ func CheckServerStatus(serverURL *url.URL, checkEndpoint string, roundTripper ht
 	if err != nil {
 		return err
 	}
-
 	if response.StatusCode != http.StatusOK {
 		return fmt.Errorf("check failed: URL=%s, status=%d", serverURL, response.StatusCode)
 	}
@@ -871,11 +805,9 @@ func CheckConfig(agentMode, checkSyntaxOnly bool, lintSettings configLintConfig,
 	failed := false
 
 	hasErrors := false
-
 	for _, f := range files {
 
 		ruleFiles, scrapeConfigs, err := checkConfig(agentMode, f, checkSyntaxOnly)
-
 		if err != nil {
 
 			fmt.Fprintln(os.Stderr, "  FAILED:", err)
@@ -883,19 +815,15 @@ func CheckConfig(agentMode, checkSyntaxOnly bool, lintSettings configLintConfig,
 			hasErrors = true
 
 			failed = true
-
 		} else {
-
 			if len(ruleFiles) > 0 {
 				fmt.Printf("  SUCCESS: %d rule files found\n", len(ruleFiles))
 			}
 
 			fmt.Printf(" SUCCESS: %s is valid prometheus config file syntax\n", f)
-
 		}
 
 		fmt.Println()
-
 		if !checkSyntaxOnly {
 
 			scrapeConfigsFailed := lintScrapeConfigs(scrapeConfigs, lintSettings)
@@ -907,15 +835,11 @@ func CheckConfig(agentMode, checkSyntaxOnly bool, lintSettings configLintConfig,
 			failed = failed || rulesFailed
 
 			hasErrors = hasErrors || rulesHaveErrors
-
 		}
-
 	}
-
 	if failed && hasErrors {
 		return failureExitCode
 	}
-
 	if failed && lintSettings.fatal {
 		return lintErrExitCode
 	}
@@ -927,9 +851,7 @@ func CheckConfig(agentMode, checkSyntaxOnly bool, lintSettings configLintConfig,
 
 func CheckWebConfig(files ...string) int {
 	failed := false
-
 	for _, f := range files {
-
 		if err := web.Validate(f); err != nil {
 
 			fmt.Fprintln(os.Stderr, f, "FAILED:", err)
@@ -937,13 +859,10 @@ func CheckWebConfig(files ...string) int {
 			failed = true
 
 			continue
-
 		}
 
 		fmt.Fprintln(os.Stderr, f, "SUCCESS")
-
 	}
-
 	if failed {
 		return failureExitCode
 	}
@@ -953,7 +872,6 @@ func CheckWebConfig(files ...string) int {
 
 func checkFileExists(fn string) error {
 	// Nothing set, nothing to error on.
-
 	if fn == "" {
 		return nil
 	}
@@ -972,7 +890,6 @@ func checkConfig(agentMode bool, filename string, checkSyntaxOnly bool) ([]strin
 	}
 
 	var ruleFiles []string
-
 	if !checkSyntaxOnly {
 		for _, rf := range cfg.RuleFiles {
 
@@ -982,26 +899,20 @@ func checkConfig(agentMode bool, filename string, checkSyntaxOnly bool) ([]strin
 			}
 
 			// If an explicit file was given, error if it is not accessible.
-
 			if !strings.Contains(rf, "*") {
-
 				if len(rfs) == 0 {
 					return nil, nil, fmt.Errorf("%q does not point to an existing file", rf)
 				}
-
 				if err := checkFileExists(rfs[0]); err != nil {
 					return nil, nil, fmt.Errorf("error checking rule file %q: %w", rfs[0], err)
 				}
-
 			}
 
 			ruleFiles = append(ruleFiles, rfs...)
-
 		}
 	}
 
 	var scfgs []*config.ScrapeConfig
-
 	if checkSyntaxOnly {
 		scfgs = cfg.ScrapeConfigs
 	} else {
@@ -1012,45 +923,33 @@ func checkConfig(agentMode bool, filename string, checkSyntaxOnly bool) ([]strin
 		if err != nil {
 			return nil, nil, fmt.Errorf("error loading scrape configs: %w", err)
 		}
-
 	}
-
 	for _, scfg := range scfgs {
-
 		if !checkSyntaxOnly && scfg.HTTPClientConfig.Authorization != nil {
 			if err := checkFileExists(scfg.HTTPClientConfig.Authorization.CredentialsFile); err != nil {
 				return nil, nil, fmt.Errorf("error checking authorization credentials or bearer token file %q: %w", scfg.HTTPClientConfig.Authorization.CredentialsFile, err)
 			}
 		}
-
 		if err := checkTLSConfig(scfg.HTTPClientConfig.TLSConfig, checkSyntaxOnly); err != nil {
 			return nil, nil, err
 		}
-
 		for _, c := range scfg.ServiceDiscoveryConfigs {
 			switch c := c.(type) {
-
 			case *kubernetes.SDConfig:
-
 				if err := checkTLSConfig(c.HTTPClientConfig.TLSConfig, checkSyntaxOnly); err != nil {
 					return nil, nil, err
 				}
-
 			case *file.SDConfig:
-
 				if checkSyntaxOnly {
 					break
 				}
-
 				for _, file := range c.Files {
 
 					files, err := filepath.Glob(file)
 					if err != nil {
 						return nil, nil, err
 					}
-
 					if len(files) != 0 {
-
 						for _, f := range files {
 
 							var targetGroups []*targetgroup.Group
@@ -1059,53 +958,39 @@ func checkConfig(agentMode bool, filename string, checkSyntaxOnly bool) ([]strin
 							if err != nil {
 								return nil, nil, fmt.Errorf("checking SD file %q: %w", file, err)
 							}
-
 							if err := checkTargetGroupsForScrapeConfig(targetGroups, scfg); err != nil {
 								return nil, nil, err
 							}
-
 						}
 
 						continue
-
 					}
 
 					fmt.Printf("  WARNING: file %q for file_sd in scrape job %q does not exist\n", file, scfg.JobName)
-
 				}
-
 			case discovery.StaticConfig:
-
 				if err := checkTargetGroupsForScrapeConfig(c, scfg); err != nil {
 					return nil, nil, err
 				}
-
 			}
 		}
-
 	}
 
 	alertConfig := cfg.AlertingConfig
-
 	for _, amcfg := range alertConfig.AlertmanagerConfigs {
 		for _, c := range amcfg.ServiceDiscoveryConfigs {
 			switch c := c.(type) {
-
 			case *file.SDConfig:
-
 				if checkSyntaxOnly {
 					break
 				}
-
 				for _, file := range c.Files {
 
 					files, err := filepath.Glob(file)
 					if err != nil {
 						return nil, nil, err
 					}
-
 					if len(files) != 0 {
-
 						for _, f := range files {
 
 							var targetGroups []*targetgroup.Group
@@ -1114,27 +999,20 @@ func checkConfig(agentMode bool, filename string, checkSyntaxOnly bool) ([]strin
 							if err != nil {
 								return nil, nil, fmt.Errorf("checking SD file %q: %w", file, err)
 							}
-
 							if err := checkTargetGroupsForAlertmanager(targetGroups, amcfg); err != nil {
 								return nil, nil, err
 							}
-
 						}
 
 						continue
-
 					}
 
 					fmt.Printf("  WARNING: file %q for file_sd in alertmanager config does not exist\n", file)
-
 				}
-
 			case discovery.StaticConfig:
-
 				if err := checkTargetGroupsForAlertmanager(c, amcfg); err != nil {
 					return nil, nil, err
 				}
-
 			}
 		}
 	}
@@ -1146,19 +1024,15 @@ func checkTLSConfig(tlsConfig promconfig.TLSConfig, checkSyntaxOnly bool) error
 	if len(tlsConfig.CertFile) > 0 && len(tlsConfig.KeyFile) == 0 {
 		return fmt.Errorf("client cert file %q specified without client key file", tlsConfig.CertFile)
 	}
-
 	if len(tlsConfig.KeyFile) > 0 && len(tlsConfig.CertFile) == 0 {
 		return fmt.Errorf("client key file %q specified without client cert file", tlsConfig.KeyFile)
 	}
-
 	if checkSyntaxOnly {
 		return nil
 	}
-
 	if err := checkFileExists(tlsConfig.CertFile); err != nil {
 		return fmt.Errorf("error checking client cert file %q: %w", tlsConfig.CertFile, err)
 	}
-
 	if err := checkFileExists(tlsConfig.KeyFile); err != nil {
 		return fmt.Errorf("error checking client key file %q: %w", tlsConfig.KeyFile, err)
 	}
@@ -1180,27 +1054,19 @@ func checkSDFile(filename string) ([]*targetgroup.Group, error) {
 	}
 
 	var targetGroups []*targetgroup.Group
-
 	switch ext := filepath.Ext(filename); strings.ToLower(ext) {
-
 	case ".json":
-
 		if err := json.Unmarshal(content, &targetGroups); err != nil {
 			return nil, err
 		}
-
 	case ".yml", ".yaml":
-
 		if err := yaml.UnmarshalStrict(content, &targetGroups); err != nil {
 			return nil, err
 		}
-
 	default:
 
 		return nil, fmt.Errorf("invalid file extension: %q", ext)
-
 	}
-
 	for i, tg := range targetGroups {
 		if tg == nil {
 			return nil, fmt.Errorf("nil target group item found (index %d)", i)
@@ -1216,17 +1082,14 @@ func CheckRules(ls rulesLintConfig, files ...string) int {
 	failed := false
 
 	hasErrors := false
-
 	if len(files) == 0 {
 		failed, hasErrors = checkRulesFromStdin(ls)
 	} else {
 		failed, hasErrors = checkRules(files, ls)
 	}
-
 	if failed && hasErrors {
 		return failureExitCode
 	}
-
 	if failed && ls.fatal {
 		return lintErrExitCode
 	}
@@ -1249,45 +1112,35 @@ func checkRulesFromStdin(ls rulesLintConfig) (bool, bool) {
 		fmt.Fprintln(os.Stderr, "  FAILED:", err)
 
 		return true, true
-
 	}
 
 	rgs, errs := rulefmt.Parse(data, ls.ignoreUnknownFields)
-
 	if errs != nil {
 
 		failed = true
 
 		fmt.Fprintln(os.Stderr, "  FAILED:")
-
 		for _, e := range errs {
 
 			fmt.Fprintln(os.Stderr, e.Error())
 
 			hasErrors = hasErrors || !errors.Is(e, errLint)
-
 		}
-
 		if hasErrors {
 			return failed, hasErrors
 		}
-
 	}
-
 	if n, errs := checkRuleGroups(rgs, ls); errs != nil {
 
 		fmt.Fprintln(os.Stderr, "  FAILED:")
-
 		for _, e := range errs {
 			fmt.Fprintln(os.Stderr, e.Error())
 		}
 
 		failed = true
-
 		for _, err := range errs {
 			hasErrors = hasErrors || !errors.Is(err, errLint)
 		}
-
 	} else {
 		fmt.Printf("  SUCCESS: %d rules found\n", n)
 	}
@@ -1303,53 +1156,42 @@ func checkRules(files []string, ls rulesLintConfig) (bool, bool) {
 	failed := false
 
 	hasErrors := false
-
 	for _, f := range files {
 
 		fmt.Println("Checking", f)
 
 		rgs, errs := rulefmt.ParseFile(f, ls.ignoreUnknownFields)
-
 		if errs != nil {
 
 			failed = true
 
 			fmt.Fprintln(os.Stderr, "  FAILED:")
-
 			for _, e := range errs {
 
 				fmt.Fprintln(os.Stderr, e.Error())
 
 				hasErrors = hasErrors || !errors.Is(e, errLint)
-
 			}
-
 			if hasErrors {
 				continue
 			}
-
 		}
-
 		if n, errs := checkRuleGroups(rgs, ls); errs != nil {
 
 			fmt.Fprintln(os.Stderr, "  FAILED:")
-
 			for _, e := range errs {
 				fmt.Fprintln(os.Stderr, e.Error())
 			}
 
 			failed = true
-
 			for _, err := range errs {
 				hasErrors = hasErrors || !errors.Is(err, errLint)
 			}
-
 		} else {
 			fmt.Printf("  SUCCESS: %d rules found\n", n)
 		}
 
 		fmt.Println()
-
 	}
 
 	return failed, hasErrors
@@ -1357,19 +1199,15 @@ func checkRules(files []string, ls rulesLintConfig) (bool, bool) {
 
 func checkRuleGroups(rgs *rulefmt.RuleGroups, lintSettings rulesLintConfig) (int, []error) {
 	numRules := 0
-
 	for _, rg := range rgs.Groups {
 		numRules += len(rg.Rules)
 	}
-
 	if lintSettings.lintDuplicateRules() {
 
 		dRules := checkDuplicates(rgs.Groups)
-
 		if len(dRules) != 0 {
 
 			errMessage := fmt.Sprintf("%d duplicate rule(s) found.\n", len(dRules))
-
 			for _, n := range dRules {
 
 				errMessage += fmt.Sprintf("Metric: %s\nLabel(s):\n", n.metric)
@@ -1377,15 +1215,12 @@ func checkRuleGroups(rgs *rulefmt.RuleGroups, lintSettings rulesLintConfig) (int
 				n.label.Range(func(l labels.Label) {
 					errMessage += fmt.Sprintf("\t%s: %s\n", l.Name, l.Value)
 				})
-
 			}
 
 			errMessage += "Might cause inconsistency while recording expressions"
 
 			return 0, []error{fmt.Errorf("%w %s", errLint, errMessage)}
-
 		}
-
 	}
 
 	return numRules, nil
@@ -1398,7 +1233,6 @@ func lintScrapeConfigs(scrapeConfigs []*config.ScrapeConfig, lintSettings config
 			fmt.Fprintf(os.Stderr, "  FAILED: too long scrape interval found, data point will be marked as stale - job: %s, interval: %s\n", scfg.JobName, scfg.ScrapeInterval)
 
 			return true
-
 		}
 	}
 
@@ -1431,7 +1265,6 @@ func checkDuplicates(groups []rulefmt.RuleGroup) []compareRuleType {
 	var duplicates []compareRuleType
 
 	var cRules compareRuleTypes
-
 	for _, group := range groups {
 		for _, rule := range group.Rules {
 			cRules = append(cRules, compareRuleType{
@@ -1441,7 +1274,6 @@ func checkDuplicates(groups []rulefmt.RuleGroup) []compareRuleType {
 			})
 		}
 	}
-
 	if len(cRules) < 2 {
 		return duplicates
 	}
@@ -1449,19 +1281,15 @@ func checkDuplicates(groups []rulefmt.RuleGroup) []compareRuleType {
 	sort.Sort(cRules)
 
 	last := cRules[0]
-
 	for i := 1; i < len(cRules); i++ {
-
 		if compare(last, cRules[i]) == 0 {
 			// Don't add a duplicated rule multiple times.
-
 			if len(duplicates) == 0 || compare(last, duplicates[len(duplicates)-1]) != 0 {
 				duplicates = append(duplicates, cRules[i])
 			}
 		}
 
 		last = cRules[i]
-
 	}
 
 	return duplicates
@@ -1478,17 +1306,8 @@ func ruleMetric(rule rulefmt.Rule) string {
 var checkMetricsUsage = strings.TrimSpace(`
 
 Pass Prometheus metrics over stdin to lint them for consistency and correctness.
-
-
-
 examples:
-
-
-
 $ cat metrics.prom | promtool check metrics
-
-
-
 $ curl -s http://localhost:9090/metrics | promtool check metrics
 
 `)
@@ -1508,17 +1327,13 @@ func CheckMetrics(extended bool) int {
 		fmt.Fprintln(os.Stderr, "error while linting:", err)
 
 		return failureExitCode
-
 	}
-
 	for _, p := range problems {
 		fmt.Fprintln(os.Stderr, p.Metric, p.Text)
 	}
-
 	if len(problems) > 0 {
 		return lintErrExitCode
 	}
-
 	if extended {
 
 		stats, total, err := checkMetricsExtended(&buf)
@@ -1527,13 +1342,11 @@ func CheckMetrics(extended bool) int {
 			fmt.Fprintln(os.Stderr, err)
 
 			return failureExitCode
-
 		}
 
 		w := tabwriter.NewWriter(os.Stdout, 4, 4, 4, ' ', tabwriter.TabIndent)
 
 		fmt.Fprintf(w, "Metric\tCardinality\tPercentage\t\n")
-
 		for _, stat := range stats {
 			fmt.Fprintf(w, "%s\t%d\t%.2f%%\t\n", stat.name, stat.cardinality, stat.percentage*100)
 		}
@@ -1541,7 +1354,6 @@ func CheckMetrics(extended bool) int {
 		fmt.Fprintf(w, "Total\t%d\t%.f%%\t\n", total, 100.)
 
 		w.Flush()
-
 	}
 
 	return successExitCode
@@ -1566,17 +1378,13 @@ func checkMetricsExtended(r io.Reader) ([]metricStat, int, error) {
 	var total int
 
 	stats := make([]metricStat, 0, len(metricFamilies))
-
 	for _, mf := range metricFamilies {
 
 		var cardinality int
-
 		switch mf.GetType() {
-
 		case dto.MetricType_COUNTER, dto.MetricType_GAUGE, dto.MetricType_UNTYPED:
 
 			cardinality = len(mf.Metric)
-
 		case dto.MetricType_HISTOGRAM:
 
 			// Histogram metrics includes sum, count, buckets.
@@ -1584,7 +1392,6 @@ func checkMetricsExtended(r io.Reader) ([]metricStat, int, error) {
 			buckets := len(mf.Metric[0].Histogram.Bucket)
 
 			cardinality = len(mf.Metric) * (2 + buckets)
-
 		case dto.MetricType_SUMMARY:
 
 			// Summary metrics includes sum, count, quantiles.
@@ -1592,19 +1399,15 @@ func checkMetricsExtended(r io.Reader) ([]metricStat, int, error) {
 			quantiles := len(mf.Metric[0].Summary.Quantile)
 
 			cardinality = len(mf.Metric) * (2 + quantiles)
-
 		default:
 
 			cardinality = len(mf.Metric)
-
 		}
 
 		stats = append(stats, metricStat{name: mf.GetName(), cardinality: cardinality})
 
 		total += cardinality
-
 	}
-
 	for i := range stats {
 		stats[i].percentage = float64(stats[i].cardinality) / float64(total)
 	}
@@ -1646,7 +1449,6 @@ var (
 				}
 
 				var buf bytes.Buffer
-
 				if err := p.WriteUncompressed(&buf); err != nil {
 					return nil, fmt.Errorf("writing the profile to the buffer: %w", err)
 				}
@@ -1685,7 +1487,6 @@ func debugPprof(url string) int {
 		fmt.Fprintln(os.Stderr, "error completing debug command:", err)
 
 		return failureExitCode
-
 	}
 
 	return successExitCode
@@ -1703,7 +1504,6 @@ func debugMetrics(url string) int {
 		fmt.Fprintln(os.Stderr, "error completing debug command:", err)
 
 		return failureExitCode
-
 	}
 
 	return successExitCode
@@ -1721,7 +1521,6 @@ func debugAll(url string) int {
 		fmt.Fprintln(os.Stderr, "error completing debug command:", err)
 
 		return failureExitCode
-
 	}
 
 	return successExitCode
@@ -1756,21 +1555,21 @@ func (p *promqlPrinter) printLabelValues(val model.LabelValues) {
 type jsonPrinter struct{}
 
 func (j *jsonPrinter) printValue(v model.Value) {
-	//nolint:errcheck
-
-	json.NewEncoder(os.Stdout).Encode(v)
+	if err := json.NewEncoder(os.Stdout).Encode(v); err != nil {
+		fmt.Fprintf(os.Stderr, "Error encoding JSON: %v\n", err)
+	}
 }
 
 func (j *jsonPrinter) printSeries(v []model.LabelSet) {
-	//nolint:errcheck
-
-	json.NewEncoder(os.Stdout).Encode(v)
+	if err := json.NewEncoder(os.Stdout).Encode(v); err != nil {
+		fmt.Fprintf(os.Stderr, "Error encoding JSON: %v\n", err)
+	}
 }
 
 func (j *jsonPrinter) printLabelValues(v model.LabelValues) {
-	//nolint:errcheck
-
-	json.NewEncoder(os.Stdout).Encode(v)
+	if err := json.NewEncoder(os.Stdout).Encode(v); err != nil {
+		fmt.Fprintf(os.Stderr, "Error encoding JSON: %v\n", err)
+	}
 }
 
 // importRules backfills recording rules from the files provided. The output are blocks of data
@@ -1783,7 +1582,6 @@ func importRules(url *url.URL, roundTripper http.RoundTripper, start, end, outpu
 	var stime, etime time.Time
 
 	var err error
-
 	if end == "" {
 		etime = time.Now().UTC().Add(-3 * time.Hour)
 	} else {
@@ -1792,14 +1590,12 @@ func importRules(url *url.URL, roundTripper http.RoundTripper, start, end, outpu
 		if err != nil {
 			return fmt.Errorf("error parsing end time: %w", err)
 		}
-
 	}
 
 	stime, err = parseTime(start)
 	if err != nil {
 		return fmt.Errorf("error parsing start time: %w", err)
 	}
-
 	if !stime.Before(etime) {
 		return errors.New("start time is not before end time")
 	}
@@ -1824,7 +1620,6 @@ func importRules(url *url.URL, roundTripper http.RoundTripper, start, end, outpu
 	ruleImporter := newRuleImporter(promslog.New(&promslog.Config{}), cfg, api)
 
 	errs := ruleImporter.loadGroups(ctx, files)
-
 	for _, err := range errs {
 		if err != nil {
 			return fmt.Errorf("rule importer parse error: %w", err)
@@ -1832,11 +1627,9 @@ func importRules(url *url.URL, roundTripper http.RoundTripper, start, end, outpu
 	}
 
 	errs = ruleImporter.importAll(ctx)
-
 	for _, err := range errs {
 		fmt.Fprintln(os.Stderr, "rule importer error:", err)
 	}
-
 	if len(errs) > 0 {
 		return errors.New("error importing rules")
 	}
@@ -1858,21 +1651,17 @@ func checkTargetGroupsForScrapeConfig(targetGroups []*targetgroup.Group, scfg *c
 	var targets []*scrape.Target
 
 	lb := labels.NewBuilder(labels.EmptyLabels())
-
 	for _, tg := range targetGroups {
 
 		var failures []error
 
 		targets, failures = scrape.TargetsFromGroup(tg, scfg, targets, lb)
-
 		if len(failures) > 0 {
 
 			first := failures[0]
 
 			return first
-
 		}
-
 	}
 
 	return nil
@@ -1896,36 +1685,28 @@ func labelsSetPromQL(query, labelMatchType, name, value string) error {
 	}
 
 	var matchType labels.MatchType
-
 	switch labelMatchType {
-
 	case parser.ItemType(parser.EQL).String():
 
 		matchType = labels.MatchEqual
-
 	case parser.ItemType(parser.NEQ).String():
 
 		matchType = labels.MatchNotEqual
-
 	case parser.ItemType(parser.EQL_REGEX).String():
 
 		matchType = labels.MatchRegexp
-
 	case parser.ItemType(parser.NEQ_REGEX).String():
 
 		matchType = labels.MatchNotRegexp
-
 	default:
 
 		return fmt.Errorf("invalid label match type: %s", labelMatchType)
-
 	}
 
 	parser.Inspect(expr, func(node parser.Node, _ []parser.Node) error {
 		if n, ok := node.(*parser.VectorSelector); ok {
 
 			var found bool
-
 			for i, l := range n.LabelMatchers {
 				if l.Name == name {
 
@@ -1934,10 +1715,8 @@ func labelsSetPromQL(query, labelMatchType, name, value string) error {
 					n.LabelMatchers[i].Value = value
 
 					found = true
-
 				}
 			}
-
 			if !found {
 				n.LabelMatchers = append(n.LabelMatchers, &labels.Matcher{
 					Type: matchType,
@@ -1947,7 +1726,6 @@ func labelsSetPromQL(query, labelMatchType, name, value string) error {
 					Value: value,
 				})
 			}
-
 		}
 
 		return nil
diff --git a/cmd/promtool/unittest.go b/cmd/promtool/unittest.go
index ac199da78..570c0a15a 100644
--- a/cmd/promtool/unittest.go
+++ b/cmd/promtool/unittest.go
@@ -159,66 +159,52 @@ func RulesUnitTestResult(results io.Writer, queryOpts promqltest.LazyLoaderOpts,
 	junit := &junitxml.JUnitXML{}
 
 	var run *regexp.Regexp
-
 	if runStrings != nil {
 		run = regexp.MustCompile(strings.Join(runStrings, "|"))
 	}
 
 	var tracker *coverageTracker
-
 	if coverage {
 		tracker = newCoverageTracker()
 	}
-
 	for _, f := range files {
-
 		if errs := ruleUnitTest(f, queryOpts, run, diffFlag, debug, ignoreUnknownFields, tracker, junit.Suite(f)); errs != nil {
 
 			fmt.Fprintln(os.Stderr, "  FAILED:")
-
 			for _, e := range errs {
 
 				fmt.Fprintln(os.Stderr, e.Error())
 
 				fmt.Println()
-
 			}
 
 			failed = true
-
 		} else {
 			fmt.Println("  SUCCESS")
 		}
 
 		fmt.Println()
-
 	}
 
 	err := junit.WriteXML(results)
 	if err != nil {
 		fmt.Fprintf(os.Stderr, "failed to write JUnit XML: %s\n", err)
 	}
-
 	if coverage && tracker != nil {
 
 		report := tracker.generateReport()
-
 		if err := outputCoverageReport(report, outputFormat, coverageOutput); err != nil {
 			fmt.Fprintf(os.Stderr, "failed to output coverage report: %s\n", err)
 		}
 
 		// Check coverage threshold
-
 		if coverageThreshold > 0 && report.Coverage < coverageThreshold {
 
 			fmt.Fprintf(os.Stderr, "Coverage %.2f%% is below threshold %.2f%%\n", report.Coverage, coverageThreshold)
 
 			return coverageExitCode
-
 		}
-
 	}
-
 	if failed {
 		return 1 // failureExitCode
 	}
@@ -233,27 +219,21 @@ func ruleUnitTest(filename string, queryOpts promqltest.LazyLoaderOpts, run *reg
 		ts.Abort(err)
 
 		return []error{err}
-
 	}
 
 	var unitTestInp unitTestFile
-
 	if err := yaml.UnmarshalStrict(b, &unitTestInp); err != nil {
 
 		ts.Abort(err)
 
 		return []error{err}
-
 	}
-
 	if err := resolveAndGlobFilepaths(filepath.Dir(filename), &unitTestInp); err != nil {
 
 		ts.Abort(err)
 
 		return []error{err}
-
 	}
-
 	if unitTestInp.EvaluationInterval == 0 {
 		unitTestInp.EvaluationInterval = model.Duration(1 * time.Minute)
 	}
@@ -267,9 +247,7 @@ func ruleUnitTest(filename string, queryOpts promqltest.LazyLoaderOpts, run *reg
 	// Lower number group should be evaluated before higher number group.
 
 	groupOrderMap := make(map[string]int)
-
 	for i, gn := range unitTestInp.GroupEvalOrder {
-
 		if _, ok := groupOrderMap[gn]; ok {
 
 			err := fmt.Errorf("group name repeated in evaluation order: %s", gn)
@@ -277,49 +255,38 @@ func ruleUnitTest(filename string, queryOpts promqltest.LazyLoaderOpts, run *reg
 			ts.Abort(err)
 
 			return []error{err}
-
 		}
 
 		groupOrderMap[gn] = i
-
 	}
 
 	// Testing.
 
 	var errs []error
-
 	for i, t := range unitTestInp.Tests {
-
 		if !matchesRun(t.TestGroupName, run) {
 			continue
 		}
 
 		testname := t.TestGroupName
-
 		if testname == "" {
 			testname = fmt.Sprintf("unnamed#%d", i)
 		}
 
 		tc := ts.Case(testname)
-
 		if t.Interval == 0 {
 			t.Interval = unitTestInp.EvaluationInterval
 		}
 
 		ers := t.test(testname, evalInterval, groupOrderMap, queryOpts, diffFlag, debug, ignoreUnknownFields, tracker, unitTestInp.FuzzyCompare, unitTestInp.RuleFiles...)
-
 		if ers != nil {
-
 			for _, e := range ers {
 				tc.Fail(e.Error())
 			}
 
 			errs = append(errs, ers...)
-
 		}
-
 	}
-
 	if len(errs) > 0 {
 		return errs
 	}
@@ -361,20 +328,17 @@ func resolveAndGlobFilepaths(baseDir string, utf *unitTestFile) error {
 	}
 
 	var globbedFiles []string
-
 	for _, rf := range utf.RuleFiles {
 
 		m, err := filepath.Glob(rf)
 		if err != nil {
 			return err
 		}
-
 		if len(m) == 0 {
 			fmt.Fprintln(os.Stderr, "  WARNING: no file match pattern", rf)
 		}
 
 		globbedFiles = append(globbedFiles, m...)
-
 	}
 
 	utf.RuleFiles = globbedFiles
@@ -412,7 +376,6 @@ func (tg *testGroup) test(testname string, evalInterval time.Duration, groupOrde
 		defer func() {
 			fmt.Printf("DEBUG: Test %s finished, took %v\n", testname, time.Since(testStart))
 		}()
-
 	}
 
 	// Setup testing suite.
@@ -448,13 +411,11 @@ func (tg *testGroup) test(testname string, evalInterval time.Duration, groupOrde
 	m := rules.NewManager(opts)
 
 	groupsMap, ers := m.LoadGroups(time.Duration(tg.Interval), tg.ExternalLabels, tg.ExternalURL, nil, ignoreUnknownFields, ruleFiles...)
-
 	if ers != nil {
 		return ers
 	}
 
 	groups := orderedGroups(groupsMap, groupOrderMap)
-
 	if tracker != nil {
 		for _, ruleFile := range ruleFiles {
 			if err := tracker.addRuleFile(ruleFile, groupsMap); err != nil {
@@ -472,7 +433,6 @@ func (tg *testGroup) test(testname string, evalInterval time.Duration, groupOrde
 	// Optional floating point compare fuzzing.
 
 	var compareFloat64 cmp.Option = cmp.Options{}
-
 	if fuzzyCompare {
 		compareFloat64 = cmp.Comparer(func(x, y float64) bool {
 			return x == y || math.Nextafter(x, math.Inf(-1)) == y || math.Nextafter(x, math.Inf(1)) == y
@@ -496,23 +456,18 @@ func (tg *testGroup) test(testname string, evalInterval time.Duration, groupOrde
 	// Map of all the unit tests for given eval_time.
 
 	alertTests := make(map[model.Duration][]alertTestCase)
-
 	for _, alert := range tg.AlertRuleTests {
-
 		if alert.Alertname == "" {
 
 			var testGroupLog string
-
 			if tg.TestGroupName != "" {
 				testGroupLog = fmt.Sprintf(" (in TestGroup %s)", tg.TestGroupName)
 			}
 
 			return []error{fmt.Errorf("an item under alert_rule_test misses required attribute alertname at eval_time %v%s", alert.EvalTime, testGroupLog)}
-
 		}
 
 		alertEvalTimesMap[alert.EvalTime] = struct{}{}
-
 		if _, ok := alertsInTest[alert.EvalTime]; !ok {
 			alertsInTest[alert.EvalTime] = make(map[string]struct{})
 		}
@@ -520,11 +475,9 @@ func (tg *testGroup) test(testname string, evalInterval time.Duration, groupOrde
 		alertsInTest[alert.EvalTime][alert.Alertname] = struct{}{}
 
 		alertTests[alert.EvalTime] = append(alertTests[alert.EvalTime], alert)
-
 	}
 
 	alertEvalTimes := make([]model.Duration, 0, len(alertEvalTimesMap))
-
 	for k := range alertEvalTimesMap {
 		alertEvalTimes = append(alertEvalTimes, k)
 	}
@@ -536,7 +489,6 @@ func (tg *testGroup) test(testname string, evalInterval time.Duration, groupOrde
 	// Current index in alertEvalTimes what we are looking at.
 
 	curr := 0
-
 	for _, g := range groups {
 		for _, r := range g.Rules() {
 			if alertRule, ok := r.(*rules.AlertingRule); ok {
@@ -550,7 +502,6 @@ func (tg *testGroup) test(testname string, evalInterval time.Duration, groupOrde
 	}
 
 	var errs []error
-
 	for ts := mint; ts.Before(maxt) || ts.Equal(maxt); ts = ts.Add(evalInterval) {
 
 		// Collects the alerts asked for unit testing.
@@ -563,13 +514,10 @@ func (tg *testGroup) test(testname string, evalInterval time.Duration, groupOrde
 				errs = append(errs, err)
 
 				return
-
 			}
-
 			for _, g := range groups {
 
 				g.Eval(suite.Context(), ts)
-
 				for _, r := range g.Rules() {
 					if r.LastError() != nil {
 						evalErrs = append(evalErrs, fmt.Errorf("    rule: %s, time: %s, err: %w",
@@ -577,7 +525,6 @@ func (tg *testGroup) test(testname string, evalInterval time.Duration, groupOrde
 							r.Name(), ts.Sub(time.Unix(0, 0).UTC()), r.LastError()))
 					}
 				}
-
 			}
 		})
 
@@ -586,11 +533,9 @@ func (tg *testGroup) test(testname string, evalInterval time.Duration, groupOrde
 		// Only end testing at this point if errors occurred evaluating above,
 
 		// rather than any test failures already collected in errs.
-
 		if len(evalErrs) > 0 {
 			return errs
 		}
-
 		for curr < len(alertEvalTimes) && ts.Sub(mint) <= time.Duration(alertEvalTimes[curr]) &&
 
 			time.Duration(alertEvalTimes[curr]) < ts.Add(evalInterval).Sub(mint) {
@@ -610,25 +555,20 @@ func (tg *testGroup) test(testname string, evalInterval time.Duration, groupOrde
 			// Same Alert name can be present in multiple groups.
 
 			// Hence we collect them all to check against expected alerts.
-
 			for _, g := range groups {
 
 				grules := g.Rules()
-
 				for _, r := range grules {
 
 					ar, ok := r.(*rules.AlertingRule)
-
 					if !ok {
 						continue
 					}
-
 					if _, ok := presentAlerts[ar.Name()]; !ok {
 						continue
 					}
 
 					var alerts labelsAndAnnotations
-
 					for _, a := range ar.ActiveAlerts() {
 						if a.State == rules.StateFiring {
 							alerts = append(alerts, labelAndAnnotation{
@@ -640,29 +580,23 @@ func (tg *testGroup) test(testname string, evalInterval time.Duration, groupOrde
 					}
 
 					got[ar.Name()] = append(got[ar.Name()], alerts...)
-
 				}
-
 			}
-
 			for _, testcase := range alertTests[t] {
 
 				// Checking alerts.
 
 				gotAlerts := got[testcase.Alertname]
-
 				if tracker != nil {
 					tracker.markRuleTested(testcase.Alertname, testname)
 				}
 
 				var expAlerts labelsAndAnnotations
-
 				for _, a := range testcase.ExpAlerts {
 
 					// User gives only the labels from alerting rule, which doesn't
 
 					// include this label (added by Prometheus during Eval).
-
 					if a.ExpLabels == nil {
 						a.ExpLabels = make(map[string]string)
 					}
@@ -674,17 +608,14 @@ func (tg *testGroup) test(testname string, evalInterval time.Duration, groupOrde
 
 						Annotations: labels.FromMap(a.ExpAnnotations),
 					})
-
 				}
 
 				sort.Sort(gotAlerts)
 
 				sort.Sort(expAlerts)
-
 				if !cmp.Equal(expAlerts, gotAlerts, cmp.Comparer(labels.Equal), compareFloat64) {
 
 					var testName string
-
 					if tg.TestGroupName != "" {
 						testName = fmt.Sprintf("    name: %s,\n", tg.TestGroupName)
 					}
@@ -692,11 +623,9 @@ func (tg *testGroup) test(testname string, evalInterval time.Duration, groupOrde
 					expString := indentLines(expAlerts.String(), "            ")
 
 					gotString := indentLines(gotAlerts.String(), "            ")
-
 					if diffFlag {
 
 						// If empty, populates an empty value
-
 						if gotAlerts.Len() == 0 {
 							gotAlerts = append(gotAlerts, labelAndAnnotation{
 								Labels: labels.Labels{},
@@ -706,7 +635,6 @@ func (tg *testGroup) test(testname string, evalInterval time.Duration, groupOrde
 						}
 
 						// If empty, populates an empty value
-
 						if expAlerts.Len() == 0 {
 							expAlerts = append(expAlerts, labelAndAnnotation{
 								Labels: labels.Labels{},
@@ -723,7 +651,6 @@ func (tg *testGroup) test(testname string, evalInterval time.Duration, groupOrde
 							errs = append(errs, fmt.Errorf("error marshaling expected %s alert: [%s]", tg.TestGroupName, err.Error()))
 
 							continue
-
 						}
 
 						gotAlertsJSON, err := json.Marshal(gotAlerts)
@@ -732,37 +659,29 @@ func (tg *testGroup) test(testname string, evalInterval time.Duration, groupOrde
 							errs = append(errs, fmt.Errorf("error marshaling received %s alert: [%s]", tg.TestGroupName, err.Error()))
 
 							continue
-
 						}
 
 						res, diff := jsondiff.Compare(expAlertsJSON, gotAlertsJSON, &diffOpts)
-
 						if res != jsondiff.FullMatch {
 							errs = append(errs, fmt.Errorf("%s    alertname: %s, time: %s, \n        diff: %v",
 
 								testName, testcase.Alertname, testcase.EvalTime.String(), indentLines(diff, "            ")))
 						}
-
 					} else {
 						errs = append(errs, fmt.Errorf("%s    alertname: %s, time: %s, \n        exp:%v, \n        got:%v",
 
 							testName, testcase.Alertname, testcase.EvalTime.String(), expString, gotString))
 					}
-
 				}
-
 			}
 
 			curr++
-
 		}
-
 	}
 
 	// Checking promql expressions.
 
 Outer:
-
 	for _, testCase := range tg.PromqlExprTests {
 
 		got, err := query(suite.Context(), testCase.Expr, mint.Add(time.Duration(testCase.EvalTime)),
@@ -775,23 +694,18 @@ Outer:
 				testCase.EvalTime.String(), err.Error()))
 
 			continue
-
 		}
-
 		if tracker != nil {
 
 			expr, parseErr := parser.ParseExpr(testCase.Expr)
-
 			if parseErr == nil {
 				tracker.markExpressionTested(expr, testname)
 			} else {
 				tracker.warnings = append(tracker.warnings, fmt.Sprintf("Failed to parse expression in test %s: %s", testname, parseErr.Error()))
 			}
-
 		}
 
 		var gotSamples []parsedSample
-
 		for _, s := range got {
 			gotSamples = append(gotSamples, parsedSample{
 				Labels: s.Metric.Copy(),
@@ -803,39 +717,29 @@ Outer:
 		}
 
 		var expSamples []parsedSample
-
 		for _, s := range testCase.ExpSamples {
 
 			lb, err := parser.ParseMetric(s.Labels)
 
 			var hist *histogram.FloatHistogram
-
 			if err == nil && s.Histogram != "" {
 
 				_, values, parseErr := parser.ParseSeriesDesc("{} " + s.Histogram)
-
 				switch {
-
 				case parseErr != nil:
 
 					err = parseErr
-
 				case len(values) != 1:
 
 					err = fmt.Errorf("expected 1 value, got %d", len(values))
-
 				case values[0].Histogram == nil:
 
 					err = fmt.Errorf("expected histogram, got %v", values[0])
-
 				default:
 
 					hist = values[0].Histogram
-
 				}
-
 			}
-
 			if err != nil {
 
 				err = fmt.Errorf("labels %q: %w", s.Labels, err)
@@ -845,7 +749,6 @@ Outer:
 					testCase.EvalTime.String(), err))
 
 				continue Outer
-
 			}
 
 			expSamples = append(expSamples, parsedSample{
@@ -855,7 +758,6 @@ Outer:
 
 				Histogram: promqltest.HistogramTestExpression(hist),
 			})
-
 		}
 
 		sort.Slice(expSamples, func(i, j int) bool {
@@ -865,15 +767,12 @@ Outer:
 		sort.Slice(gotSamples, func(i, j int) bool {
 			return labels.Compare(gotSamples[i].Labels, gotSamples[j].Labels) <= 0
 		})
-
 		if !cmp.Equal(expSamples, gotSamples, cmp.Comparer(labels.Equal), compareFloat64) {
 			errs = append(errs, fmt.Errorf("    expr: %q, time: %s,\n        exp: %v\n        got: %v", testCase.Expr,
 
 				testCase.EvalTime.String(), parsedSamplesString(expSamples), parsedSamplesString(gotSamples)))
 		}
-
 	}
-
 	if debug {
 
 		ts := tg.maxEvalTime()
@@ -892,37 +791,28 @@ Outer:
 			fmt.Printf("DEBUG: Failed querying, expr: %q, err: %v\n", expr, err)
 
 			return errs
-
 		}
 
 		res := q.Exec(suite.Context())
-
 		if res.Err != nil {
 
 			fmt.Printf("DEBUG: Failed query exec, expr: %q, err: %v\n", expr, res.Err)
 
 			return errs
-
 		}
-
 		switch v := res.Value.(type) {
-
 		case promql.Matrix:
 
 			fmt.Printf("DEBUG: Dump of all data (input_series and rules) at %v:\n", ts)
 
 			fmt.Println(v.String())
-
 		default:
 
 			fmt.Printf("DEBUG: Got unexpected type %T\n", v)
 
 			return errs
-
 		}
-
 	}
-
 	if len(errs) > 0 {
 		return errs
 	}
@@ -934,7 +824,6 @@ Outer:
 
 func (tg *testGroup) seriesLoadingString() string {
 	result := fmt.Sprintf("load %v\n", shortDuration(tg.Interval))
-
 	for _, is := range tg.InputSeries {
 		result += fmt.Sprintf("  %v %v\n", is.Series, is.Values)
 	}
@@ -944,11 +833,9 @@ func (tg *testGroup) seriesLoadingString() string {
 
 func shortDuration(d model.Duration) string {
 	s := d.String()
-
 	if strings.HasSuffix(s, "m0s") {
 		s = s[:len(s)-2]
 	}
-
 	if strings.HasSuffix(s, "h0m") {
 		s = s[:len(s)-2]
 	}
@@ -962,7 +849,6 @@ func shortDuration(d model.Duration) string {
 
 func orderedGroups(groupsMap map[string]*rules.Group, groupOrderMap map[string]int) []*rules.Group {
 	groups := make([]*rules.Group, 0, len(groupsMap))
-
 	for _, g := range groupsMap {
 		groups = append(groups, g)
 	}
@@ -978,13 +864,11 @@ func orderedGroups(groupsMap map[string]*rules.Group, groupOrderMap map[string]i
 
 func (tg *testGroup) maxEvalTime() time.Duration {
 	var maxd model.Duration
-
 	for _, alert := range tg.AlertRuleTests {
 		if alert.EvalTime > maxd {
 			maxd = alert.EvalTime
 		}
 	}
-
 	for _, pet := range tg.PromqlExprTests {
 		if pet.EvalTime > maxd {
 			maxd = pet.EvalTime
@@ -1001,17 +885,13 @@ func query(ctx context.Context, qs string, t time.Time, engine *promql.Engine, q
 	}
 
 	res := q.Exec(ctx)
-
 	if res.Err != nil {
 		return nil, res.Err
 	}
-
 	switch v := res.Value.(type) {
-
 	case promql.Vector:
 
 		return v, nil
-
 	case promql.Scalar:
 
 		return promql.Vector{promql.Sample{
@@ -1021,11 +901,9 @@ func query(ctx context.Context, qs string, t time.Time, engine *promql.Engine, q
 
 			Metric: labels.Labels{},
 		}}, nil
-
 	default:
 
 		return nil, errors.New("rule result is not a vector or scalar")
-
 	}
 }
 
@@ -1037,19 +915,15 @@ func indentLines(lines, indent string) string {
 	sb := strings.Builder{}
 
 	n := strings.Split(lines, "\n")
-
 	for i, l := range n {
-
 		if i > 0 {
 			sb.WriteString(indent)
 		}
 
 		sb.WriteString(l)
-
 		if i != len(n)-1 {
 			sb.WriteRune('\n')
 		}
-
 	}
 
 	return sb.String()
@@ -1063,7 +937,6 @@ func (la labelsAndAnnotations) Swap(i, j int) { la[i], la[j] = la[j], la[i] }
 
 func (la labelsAndAnnotations) Less(i, j int) bool {
 	diff := labels.Compare(la[i].Labels, la[j].Labels)
-
 	if diff != 0 {
 		return diff < 0
 	}
@@ -1077,7 +950,6 @@ func (la labelsAndAnnotations) String() string {
 	}
 
 	s := "[\n0:" + indentLines("\n"+la[0].String(), "  ")
-
 	for i, l := range la[1:] {
 		s += ",\n" + strconv.Itoa(i+1) + ":" + indentLines("\n"+l.String(), "  ")
 	}
@@ -1149,7 +1021,6 @@ func parsedSamplesString(pss []parsedSample) string {
 	}
 
 	s := pss[0].String()
-
 	for _, ps := range pss[1:] {
 		s += ", " + ps.String()
 	}
@@ -1189,14 +1060,12 @@ func (ct *coverageTracker) addRuleFile(filename string, groups map[string]*rules
 	ct.allRules[filename] = make(map[string]*ruleInfo)
 
 	ct.testedRules[filename] = make(map[string]bool)
-
 	for _, group := range groups {
 		for _, rule := range group.Rules() {
 
 			ruleName := rule.Name()
 
 			ruleType := "recording"
-
 			if _, ok := rule.(*rules.AlertingRule); ok {
 				ruleType = "alerting"
 			}
@@ -1214,7 +1083,6 @@ func (ct *coverageTracker) addRuleFile(filename string, groups map[string]*rules
 			}
 
 			ct.extractDependencies(ruleName, rule.Query())
-
 		}
 	}
 
@@ -1228,31 +1096,23 @@ func (ct *coverageTracker) extractDependencies(ruleName string, expr parser.Expr
 
 	parser.Inspect(expr, func(node parser.Node, _ []parser.Node) error {
 		switch n := node.(type) {
-
 		case *parser.VectorSelector:
 
 			metricName := n.Name
-
 			if metricName != "" && metricName != ruleName && !seenMetrics[metricName] {
 
 				dependencies = append(dependencies, metricName)
 
 				seenMetrics[metricName] = true
-
 			}
-
 		case *parser.MatrixSelector:
-
 			if vs, ok := n.VectorSelector.(*parser.VectorSelector); ok && vs.Name != "" && vs.Name != ruleName && !seenMetrics[vs.Name] {
 
 				dependencies = append(dependencies, vs.Name)
 
 				seenMetrics[vs.Name] = true
-
 			}
-
 		case *parser.Call:
-
 			if n.Func != nil {
 
 				// Track function usage
@@ -1260,64 +1120,49 @@ func (ct *coverageTracker) extractDependencies(ruleName string, expr parser.Expr
 				funcName := n.Func.Name
 
 				found := false
-
 				for _, f := range ct.complexity.FunctionsUsed {
 					if f == funcName {
 
 						found = true
 
 						break
-
 					}
 				}
-
 				if !found {
 					ct.complexity.FunctionsUsed = append(ct.complexity.FunctionsUsed, funcName)
 				}
-
 				switch funcName {
-
 				case "label_replace", "label_join":
 
 					ct.warnings = append(ct.warnings, fmt.Sprintf("Complex function %s in rule %s may affect coverage calculation", funcName, ruleName))
 
 					ct.complexity.ComplexExpressions++
-
 				case "absent", "absent_over_time":
 
 					ct.warnings = append(ct.warnings, fmt.Sprintf("Function %s in rule %s may reference metrics that don't exist in test data", funcName, ruleName))
-
 				case "group_left", "group_right":
 
 					ct.warnings = append(ct.warnings, fmt.Sprintf("Complex aggregation %s in rule %s may affect dependency tracking", funcName, ruleName))
 
 					ct.complexity.ComplexExpressions++
-
 				}
-
 			}
-
 		case *parser.BinaryExpr:
-
 			if n.VectorMatching != nil && (n.VectorMatching.On || len(n.VectorMatching.MatchingLabels) > 0) {
 
 				ct.warnings = append(ct.warnings, fmt.Sprintf("Complex vector matching in rule %s may affect coverage calculation", ruleName))
 
 				ct.complexity.ComplexExpressions++
-
 			}
-
 		case *parser.SubqueryExpr:
 
 			ct.warnings = append(ct.warnings, fmt.Sprintf("Subquery in rule %s may reference additional time ranges", ruleName))
 
 			ct.complexity.SubqueriesUsed++
-
 		}
 
 		return nil
 	})
-
 	if len(dependencies) > 0 {
 		ct.dependencies[ruleName] = dependencies
 	}
@@ -1325,14 +1170,12 @@ func (ct *coverageTracker) extractDependencies(ruleName string, expr parser.Expr
 
 func (ct *coverageTracker) markRuleTested(ruleName, testCase string) {
 	ct.testCases[testCase] = true
-
 	for filename := range ct.allRules {
 		if _, exists := ct.allRules[filename][ruleName]; exists {
 
 			ct.testedRules[filename][ruleName] = true
 
 			ct.testCaseMapping[ruleName] = append(ct.testCaseMapping[ruleName], testCase)
-
 			if deps, hasDeps := ct.dependencies[ruleName]; hasDeps {
 				for _, dep := range deps {
 					ct.markRuleTested(dep, testCase)
@@ -1340,7 +1183,6 @@ func (ct *coverageTracker) markRuleTested(ruleName, testCase string) {
 			}
 
 			break
-
 		}
 	}
 }
@@ -1348,9 +1190,7 @@ func (ct *coverageTracker) markRuleTested(ruleName, testCase string) {
 func (ct *coverageTracker) markExpressionTested(expr parser.Expr, testCase string) {
 	parser.Inspect(expr, func(node parser.Node, _ []parser.Node) error {
 		switch n := node.(type) {
-
 		case *parser.VectorSelector:
-
 			if n.Name != "" {
 				ct.markRuleTested(n.Name, testCase)
 			}
@@ -1358,21 +1198,16 @@ func (ct *coverageTracker) markExpressionTested(expr parser.Expr, testCase strin
 			// Also check for dynamic metric name references in label matchers
 
 			ct.checkLabelMatchers(n.LabelMatchers, testCase)
-
 		case *parser.MatrixSelector:
-
 			if vs, ok := n.VectorSelector.(*parser.VectorSelector); ok && vs.Name != "" {
 
 				ct.markRuleTested(vs.Name, testCase)
 
 				ct.checkLabelMatchers(vs.LabelMatchers, testCase)
-
 			}
-
 		case *parser.Call:
 
 			// Handle functions that might reference other metrics indirectly
-
 			if n.Func != nil {
 				switch n.Func.Name {
 				case "label_replace", "label_join":
@@ -1382,7 +1217,6 @@ func (ct *coverageTracker) markExpressionTested(expr parser.Expr, testCase strin
 					ct.extractFunctionDependencies(n, testCase)
 				}
 			}
-
 		}
 
 		return nil
@@ -1394,20 +1228,17 @@ func (ct *coverageTracker) checkLabelMatchers(matchers []*labels.Matcher, testCa
 		if matcher.Type == labels.MatchRegexp || matcher.Type == labels.MatchNotRegexp {
 
 			ct.complexity.RegexMatchers++
-
 			if matcher.Name == "__name__" {
 				// Handle regex patterns on __name__ that might match multiple metrics
 
 				ct.warnings = append(ct.warnings, fmt.Sprintf("Regex pattern on __name__ in test %s may match multiple metrics, coverage tracking may be incomplete", testCase))
 			}
-
 		}
 	}
 }
 
 func (ct *coverageTracker) extractFunctionDependencies(call *parser.Call, testCase string) {
 	// For complex functions, we can try to extract metric references from arguments
-
 	for _, arg := range call.Args {
 		if vs, ok := arg.(*parser.VectorSelector); ok && vs.Name != "" {
 			ct.markRuleTested(vs.Name, testCase)
@@ -1429,7 +1260,6 @@ func (ct *coverageTracker) generateReport() *coverageReport {
 	alertingTested := 0
 
 	files := make(map[string]*fileCoverageInfo)
-
 	for filename, rules := range ct.allRules {
 
 		fileInfo := &fileCoverageInfo{
@@ -1441,19 +1271,16 @@ func (ct *coverageTracker) generateReport() *coverageReport {
 		fileTotalRules := 0
 
 		fileTestedRules := 0
-
 		for ruleName, ruleInfo := range rules {
 
 			tested := ct.testedRules[filename][ruleName]
 
 			testCases := ct.testCaseMapping[ruleName]
-
 			if len(testCases) > 0 && !tested {
 
 				tested = true
 
 				ct.testedRules[filename][ruleName] = true
-
 			}
 
 			fileInfo.Rules[ruleName] = &ruleCoverageInfo{
@@ -1467,37 +1294,30 @@ func (ct *coverageTracker) generateReport() *coverageReport {
 			}
 
 			fileTotalRules++
-
 			if tested {
 				fileTestedRules++
 			}
 
 			// Track rule type metrics
-
 			switch ruleInfo.Type {
 			case "recording":
 
 				recordingTotal++
-
 				if tested {
 					recordingTested++
 				}
 			case "alerting":
 
 				alertingTotal++
-
 				if tested {
 					alertingTested++
 				}
-
 			}
-
 		}
 
 		fileInfo.TotalRules = fileTotalRules
 
 		fileInfo.TestedRules = fileTestedRules
-
 		if fileTotalRules > 0 {
 			fileInfo.Coverage = float64(fileTestedRules) / float64(fileTotalRules) * 100
 		}
@@ -1507,23 +1327,19 @@ func (ct *coverageTracker) generateReport() *coverageReport {
 		totalRules += fileTotalRules
 
 		testedRules += fileTestedRules
-
 	}
 
 	coverage := 0.0
-
 	if totalRules > 0 {
 		coverage = float64(testedRules) / float64(totalRules) * 100
 	}
 
 	recordingCoverage := 0.0
-
 	if recordingTotal > 0 {
 		recordingCoverage = float64(recordingTested) / float64(recordingTotal) * 100
 	}
 
 	alertingCoverage := 0.0
-
 	if alertingTotal > 0 {
 		alertingCoverage = float64(alertingTested) / float64(alertingTotal) * 100
 	}
@@ -1563,7 +1379,6 @@ func (ct *coverageTracker) generateReport() *coverageReport {
 
 func outputCoverageReport(report *coverageReport, format, outputFile string) error {
 	var output io.Writer
-
 	if outputFile != "" {
 
 		file, err := os.Create(outputFile)
@@ -1574,13 +1389,10 @@ func outputCoverageReport(report *coverageReport, format, outputFile string) err
 		defer file.Close()
 
 		output = file
-
 	} else {
 		output = os.Stdout
 	}
-
 	switch format {
-
 	case "json":
 
 		encoder := json.NewEncoder(output)
@@ -1588,15 +1400,12 @@ func outputCoverageReport(report *coverageReport, format, outputFile string) err
 		encoder.SetIndent("", "  ")
 
 		return encoder.Encode(report)
-
 	case "junit-xml":
 
 		return outputCoverageJUnit(report, output)
-
 	default: // text
 
 		return outputCoverageText(report, output)
-
 	}
 }
 
@@ -1610,73 +1419,56 @@ func outputCoverageText(report *coverageReport, output io.Writer) error {
 	fmt.Fprintf(output, "Tested Rules: %d\n", report.TestedRules)
 
 	fmt.Fprintf(output, "Overall Coverage: %.2f%%\n", report.Coverage)
-
 	if report.RecordingRules != nil {
 		fmt.Fprintf(output, "Recording Rules: %.2f%% (%d/%d)\n", report.RecordingRules.Coverage, report.RecordingRules.Tested, report.RecordingRules.Total)
 	}
-
 	if report.AlertingRules != nil {
 		fmt.Fprintf(output, "Alerting Rules: %.2f%% (%d/%d)\n", report.AlertingRules.Coverage, report.AlertingRules.Tested, report.AlertingRules.Total)
 	}
 
 	fmt.Fprintf(output, "Test Cases: %d\n", report.TestCaseCount)
-
 	if report.ComplexityMetrics != nil {
 
 		fmt.Fprintf(output, "\nComplexity Metrics:\n")
-
 		if len(report.ComplexityMetrics.FunctionsUsed) > 0 {
 			fmt.Fprintf(output, "  Functions Used: %s\n", strings.Join(report.ComplexityMetrics.FunctionsUsed, ", "))
 		}
-
 		if report.ComplexityMetrics.ComplexExpressions > 0 {
 			fmt.Fprintf(output, "  Complex Expressions: %d\n", report.ComplexityMetrics.ComplexExpressions)
 		}
-
 		if report.ComplexityMetrics.SubqueriesUsed > 0 {
 			fmt.Fprintf(output, "  Subqueries Used: %d\n", report.ComplexityMetrics.SubqueriesUsed)
 		}
-
 		if report.ComplexityMetrics.RegexMatchers > 0 {
 			fmt.Fprintf(output, "  Regex Matchers: %d\n", report.ComplexityMetrics.RegexMatchers)
 		}
-
 	}
-
 	if len(report.Warnings) > 0 {
 
 		fmt.Fprintf(output, "\nWarnings:\n")
-
 		for _, warning := range report.Warnings {
 			fmt.Fprintf(output, "  - %s\n", warning)
 		}
-
 	}
 
 	fmt.Fprintf(output, "\nFile Coverage:\n")
-
 	for filename, fileInfo := range report.Files {
 
 		fmt.Fprintf(output, "  %s: %.2f%% (%d/%d)\n", filename, fileInfo.Coverage, fileInfo.TestedRules, fileInfo.TotalRules)
-
 		for ruleName, ruleInfo := range fileInfo.Rules {
 
 			status := "✗"
-
 			if ruleInfo.Tested {
 				status = "✓"
 			}
 
 			fmt.Fprintf(output, "    %s %s (%s)\n", status, ruleName, ruleInfo.Type)
-
 			if len(ruleInfo.TestCases) > 0 {
 				fmt.Fprintf(output, "      Tested by: %s\n", strings.Join(ruleInfo.TestCases, ", "))
 			}
-
 		}
 
 		fmt.Fprintf(output, "\n")
-
 	}
 
 	return nil
@@ -1690,16 +1482,13 @@ func outputCoverageJUnit(report *coverageReport, output io.Writer) error {
 	suite.Case(fmt.Sprintf("Coverage: %.2f%% (%d/%d rules tested)",
 
 		report.Coverage, report.TestedRules, report.TotalRules))
-
 	for filename, fileInfo := range report.Files {
 		for ruleName, ruleInfo := range fileInfo.Rules {
 
 			suite.Case(fmt.Sprintf("%s:%s", filename, ruleName))
-
 			if !ruleInfo.Tested {
 				suite.Fail("Rule not covered by any test")
 			}
-
 		}
 	}
 
diff --git a/cmd/promtool/unittest_test.go b/cmd/promtool/unittest_test.go
index 0b0d14a7f..04849a6c0 100644
--- a/cmd/promtool/unittest_test.go
+++ b/cmd/promtool/unittest_test.go
@@ -188,9 +188,7 @@ func TestRulesUnitTest(t *testing.T) {
 	reuseFiles := []string{}
 
 	reuseCount := [2]int{}
-
 	for _, tt := range tests {
-
 		if (tt.queryOpts == promqltest.LazyLoaderOpts{
 			EnableNegativeOffset: true,
 		} || tt.queryOpts == promqltest.LazyLoaderOpts{
@@ -200,24 +198,20 @@ func TestRulesUnitTest(t *testing.T) {
 			reuseFiles = append(reuseFiles, tt.args.files...)
 
 			reuseCount[tt.want] += len(tt.args.files)
-
 		}
 
 		t.Run(tt.name, func(t *testing.T) {
 			t.Parallel()
-
 			if got := RulesUnitTest(tt.queryOpts, nil, false, false, false, tt.args.files...); got != tt.want {
 				t.Errorf("RulesUnitTest() = %v, want %v", got, tt.want)
 			}
 		})
-
 	}
 
 	t.Run("Junit xml output ", func(t *testing.T) {
 		t.Parallel()
 
 		var buf bytes.Buffer
-
 		if got := RulesUnitTestResult(&buf, promqltest.LazyLoaderOpts{}, nil, false, false, false, false, "text", "", 0.0, reuseFiles...); got != 1 {
 			t.Errorf("RulesUnitTestResults() = %v, want 1", got)
 		}
@@ -232,7 +226,6 @@ func TestRulesUnitTest(t *testing.T) {
 			fmt.Println("error in decoding XML:", err)
 
 			return
-
 		}
 
 		var total int
@@ -244,13 +237,10 @@ func TestRulesUnitTest(t *testing.T) {
 		var cases int
 
 		total = len(test.Suites)
-
 		if total != len(reuseFiles) {
 			t.Errorf("JUnit output had %d testsuite elements; expected %d\n", total, len(reuseFiles))
 		}
-
 		for _, i := range test.Suites {
-
 			if i.FailureCount == 0 {
 				passes++
 			} else {
@@ -258,13 +248,10 @@ func TestRulesUnitTest(t *testing.T) {
 			}
 
 			cases += len(i.Cases)
-
 		}
-
 		if total != passes+failures {
 			t.Errorf("JUnit output mismatch: Total testsuites (%d) does not equal the sum of passes (%d) and failures (%d).", total, passes, failures)
 		}
-
 		if cases < total {
 			t.Errorf("JUnit output had %d suites without test cases\n", total-cases)
 		}
@@ -385,7 +372,6 @@ func TestRulesUnitTestRun(t *testing.T) {
 			want: 1,
 		},
 	}
-
 	for _, tt := range tests {
 		t.Run(tt.name, func(t *testing.T) {
 			t.Parallel()
@@ -429,7 +415,6 @@ func TestRulesUnitTestCoverage(t *testing.T) {
 			want: 0,
 		},
 	}
-
 	for _, tt := range tests {
 		t.Run(tt.name, func(t *testing.T) {
 			t.Parallel()
@@ -529,7 +514,6 @@ func TestCoverageOutputFormats(t *testing.T) {
 
 		{"JUnit XML format", "junit-xml"},
 	}
-
 	for _, tt := range tests {
 		t.Run(tt.name, func(t *testing.T) {
 			t.Parallel()
